{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Running Quantization-Aware Training (QAT) on Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll build on top of Tutorial 2 by taking the Bert model fine tuned for sequence classification and running Mase's quantization pass. First, we'll run simple Post-Training Quantization (PTQ) and see how much accuracy drops. Then, we'll run some further training iterations of the quantized model (i.e. QAT) and see whether the accuracy of the trained quantized model approaches the accuracy of the original (full-precision) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting from scratch, you can create a MaseGraph for Bert by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3173e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3173e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4520e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3173e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5481e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7115,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7115,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7115,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3928, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1797e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3449e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1797e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3449e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4199e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6227e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1797e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1238e-02,  3.8892e-01,  ...,  1.3449e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1299e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6853e-01, -8.0782e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6710e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1034e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7657e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6627e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4397e-02, -6.9034e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3789e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6667e-03, -5.7117e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5915e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4081e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6070e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3789e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7657e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6627e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4397e-02, -6.9034e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6667e-03, -5.7117e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5915e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4081e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6070e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0894, 0.1709],\n",
      "        [0.2159, 0.2194]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously ran the tutorial on LoRA Finetuning, run the following cell to import the fine tuned checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Quantization (PTQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply quantize the model and evaluate the effect in its accuracy. First, let's evaluate the model accuracy before quantization (if you're coming from Tutorial 2, this should be the same as the post-LoRA evaluation accuracy). As seen in Tutorial 2, we can use the `get_tokenized_dataset` and `get_trainer` utilities to generate a HuggingFace `Trainer` instance for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Map:  76%|  | 19000/25000 [00:05<00:01, 5030.52 examples/s]Exception ignored in: <function Dataset.__del__ at 0x1675e27a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/souparna/mase/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py\", line 1418, in __del__\n",
      "    if hasattr(self, \"_indices\"):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Map: 100%|| 25000/25000 [00:07<00:00, 3281.65 examples/s]\n",
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='606' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 606/3125 00:14 < 01:01, 41.16 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      9\u001b[39m trainer = get_trainer(\n\u001b[32m     10\u001b[39m     model=mg.model,\n\u001b[32m     11\u001b[39m     tokenized_dataset=dataset,\n\u001b[32m     12\u001b[39m     tokenizer=tokenizer,\n\u001b[32m     13\u001b[39m     evaluate_metric=\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Evaluate accuracy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m eval_results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEvaluation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_results[\u001b[33m'\u001b[39m\u001b[33meval_accuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/transformers/trainer.py:4154\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4151\u001b[39m start_time = time.time()\n\u001b[32m   4153\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4154\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4162\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4164\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/transformers/trainer.py:4348\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4345\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4347\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4348\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4349\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4350\u001b[39m inputs_decode = (\n\u001b[32m   4351\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4352\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/transformers/trainer.py:4564\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4563\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4564\u001b[39m         loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4565\u001b[39m     loss = loss.detach().mean()\n\u001b[32m   4567\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/transformers/trainer.py:3801\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3799\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3800\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3801\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3803\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/fx/graph_module.py:822\u001b[39m, in \u001b[36mGraphModule.recompile.<locals>.call_wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/fx/graph_module.py:387\u001b[39m, in \u001b[36m_WrappedCall.__call__\u001b[39m\u001b[34m(self, obj, *args, **kwargs)\u001b[39m\n\u001b[32m    385\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cls_call(obj, *args, **kwargs)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m e.__traceback__\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<eval_with_key>.14 from <eval_with_key>.13:11 in forward:16\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, input_ids, attention_mask, labels)\u001b[39m\n\u001b[32m     14\u001b[39m add = getitem_3 + \u001b[32m0\u001b[39m;  getitem_3 = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     15\u001b[39m getitem_4 = bert_embeddings_position_ids[(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;28mslice\u001b[39m(\u001b[32m0\u001b[39m, add, \u001b[38;5;28;01mNone\u001b[39;00m))];  bert_embeddings_position_ids = add = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m bert_embeddings_word_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m;  input_ids = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     17\u001b[39m bert_embeddings_token_type_embeddings = \u001b[38;5;28mself\u001b[39m.bert.embeddings.token_type_embeddings(expand);  expand = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m add_1 = bert_embeddings_word_embeddings + bert_embeddings_token_type_embeddings;  bert_embeddings_word_embeddings = bert_embeddings_token_type_embeddings = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/nn/modules/sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mase/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the quantization pass, we pass a quantization configuration dictionary as argument. This defines the quantization mode, numerical format and precision for each operator in the graph. We'll run the quantization in \"by type\" mode, meaning nodes are quantized according to their `mase_op`. Other modes include by name and by regex name. We'll quantize all activations, weights and biases in the model to fixed-point with the same precision. This may be sub-optimal, but works as an example. In future tutorials, we'll see how to run the `search` flow in `Mase` to find optimal quantization configurations to minimize accuracy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\", # Sets to select the layers to quatisation via the type of the layers, e.g. linear or conv\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = passes.quantize_transform_pass(\n",
    "    mg,\n",
    "    pass_args=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the immediate effect of quantization on the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.77644\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the current checkpoint for future reference (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /Users/souparna/tutorial_3_ptq.pt, /Users/souparna/tutorial_3_ptq.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /Users/souparna/tutorial_3_ptq.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /Users/souparna/tutorial_3_ptq.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_3_ptq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization-Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen in the last section that quantization can lead to a significant drop in accuracy. Next, we'll run QAT to evaluate whether this performance gap can be reduced. To run QAT in Mase, all you need to do is include the model back in your training loop after running the quantization pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 501/3125 [00:36<02:57, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4017, 'grad_norm': 10.568283081054688, 'learning_rate': 4.2e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 1000/3125 [00:59<01:57, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3918, 'grad_norm': 7.2999749183654785, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 1501/3125 [01:21<00:53, 30.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3987, 'grad_norm': 11.782495498657227, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 2000/3125 [01:41<01:07, 16.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3906, 'grad_norm': 6.373114585876465, 'learning_rate': 1.8e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 2504/3125 [01:59<00:20, 30.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.382, 'grad_norm': 8.522379875183105, 'learning_rate': 1e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 3000/3125 [02:15<00:04, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3914, 'grad_norm': 10.293235778808594, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3125/3125 [02:20<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 140.3713, 'train_samples_per_second': 178.099, 'train_steps_per_second': 22.262, 'train_loss': 0.3934635339355469, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3125/3125 [00:51<00:00, 60.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.84232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy of the quantized model can match (or sometimes exceed) the full precision model, with a much lower memory requirement to store the weights. Finally, save the final checkpoint for future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /Users/souparna/tutorial_3_qat.pt, /Users/souparna/tutorial_3_qat.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /Users/souparna/tutorial_3_qat.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /Users/souparna/tutorial_3_qat.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_3_qat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Map: 100%|| 50000/50000 [00:12<00:00, 4112.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")\n",
    "\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different quantisation levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.5 with quantisation 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.5 with quantisation 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.79808 with quantisation 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.409600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.389100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.83936 with quantisation 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.83492 with quantisation 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.382800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.387000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.8416 with quantisation 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.83472 with quantisation 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.381100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.384400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.84192 with quantisation 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.8358 with quantisation 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.384100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.84192 with quantisation 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.83556 with quantisation 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.398800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.384100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.84192 with quantisation 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 04:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.83556 with quantisation 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.84176 with quantisation 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souparna/mase/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 05:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PTQ Evaluation accuracy: 0.83564 with quantisation 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " QAT Evaluation accuracy: 0.84192 with quantisation 32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt \n",
    "\n",
    "ptq_list = []\n",
    "qat_list = []\n",
    "\n",
    "\n",
    "for ql in range (4,33,4): \n",
    "\n",
    "    # Quantise\n",
    "    \n",
    "    quantization_config = {\n",
    "        \"by\": \"type\", # Sets to select the layers to quatisation via the type of the layers, e.g. linear or conv\n",
    "        \"default\": {\n",
    "            \"config\": {\n",
    "                \"name\": None,\n",
    "            }\n",
    "        },\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                # data\n",
    "                \"data_in_width\": ql,\n",
    "                \"data_in_frac_width\": ql / 2 ,\n",
    "                # weight\n",
    "                \"weight_width\": ql,\n",
    "                \"weight_frac_width\": ql / 2,\n",
    "                # bias\n",
    "                \"bias_width\": ql,\n",
    "                \"bias_frac_width\": ql / 2,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    q_mg, _ = passes.quantize_transform_pass(\n",
    "        mg,\n",
    "        pass_args=quantization_config,\n",
    "    )\n",
    "    trainer = get_trainer(\n",
    "        model=q_mg.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "    \n",
    "    # PTQ\n",
    "    \n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\" PTQ Evaluation accuracy: {eval_results['eval_accuracy']} with quantisation {ql}\")\n",
    "    ptq_list.append(eval_results['eval_accuracy'])\n",
    "    \n",
    "    # QAT \n",
    "    \n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\" QAT Evaluation accuracy: {eval_results['eval_accuracy']} with quantisation {ql}\")\n",
    "    \n",
    "    qat_list.append(eval_results['eval_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.79808, 0.83492, 0.83472, 0.8358, 0.83556, 0.83556, 0.83564]\n"
     ]
    }
   ],
   "source": [
    "print(ptq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.83936, 0.8416, 0.84192, 0.84192, 0.84192, 0.84176, 0.84192]\n"
     ]
    }
   ],
   "source": [
    "print(qat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bit_widths = list(range(4, 33, 4))  # [4, 8, 12, 16, 20, 24, 28, 32]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot PTQ and QAT curves\n",
    "plt.plot(bit_widths, ptq_list, 'o-', label='PTQ (Post-Training Quantization)', \n",
    "         color='blue', linewidth=2, markersize=8)\n",
    "plt.plot(bit_widths, qat_list, 's-', label='QAT (Quantization-Aware Training)', \n",
    "         color='red', linewidth=2, markersize=8)\n",
    "\n",
    "# Add baseline (full precision) accuracy if available\n",
    "baseline_accuracy = 0.83452  # From your earlier evaluation\n",
    "plt.axhline(y=baseline_accuracy, color='green', linestyle='--', \n",
    "            label=f'Full Precision Baseline ({baseline_accuracy:.4f})', linewidth=1.5)\n",
    "\n",
    "plt.xlabel('Bit Width (Precision)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Effect of Post-Quantization Finetuning: PTQ vs QAT', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(bit_widths)\n",
    "plt.ylim(0.45, 0.90)\n",
    "\n",
    "# Annotate the accuracy improvement at each precision\n",
    "for i, bw in enumerate(bit_widths):\n",
    "    if i < len(ptq_list) and i < len(qat_list):\n",
    "        improvement = qat_list[i] - ptq_list[i]\n",
    "        if improvement > 0.01:  # Only annotate significant improvements\n",
    "            mid_y = (ptq_list[i] + qat_list[i]) / 2\n",
    "            plt.annotate(f'+{improvement:.2%}', xy=(bw, mid_y), \n",
    "                        fontsize=9, ha='left', color='darkgreen')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
